{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we examine specific declared vocabulary terms from the USGS Thesaurus and for geographic place names in metadata that we are building into the graph to determine whether or not the terms are actually found in an associated vocabulary. We put these specific terms into a data file that can be loaded into our graph and then limit processing of related items to just those cases where we are matching defined and referenceable terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import isaid_helpers\n",
    "import datetime\n",
    "import requests\n",
    "import click\n",
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to work through the entire SDC database to evaluate all terms claiming to be from the USGS Thesaurus and all supposed place name keywords. This code gets the raw SDC from our local cache and builds lists of unique terms in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_cache = pickle.load(open(isaid_helpers.f_raw_sdc, \"rb\"))\n",
    "\n",
    "declared_terms = list()\n",
    "for item in [i for i in sdc_cache if \"usgsThesaurusKeyword\" in i]:\n",
    "    declared_terms.extend(item[\"usgsThesaurusKeyword\"])\n",
    "declared_terms = [{\"term\": i} for i in list(set(declared_terms))]\n",
    "\n",
    "declared_places = list()\n",
    "for item in [i for i in sdc_cache if \"placeKeyword\" in i]:\n",
    "    declared_places.extend(item[\"placeKeyword\"])\n",
    "declared_places = [{\"term\": i} for i in list(set(declared_places))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two functions handle the parallel processing of all terms against the reference datasets, making a few logical choices to set up reference data that can be used to create entities in our graph that can be linked to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_eval = list()\n",
    "def accumulator(term):\n",
    "    matching_terms = [\n",
    "        i for i in all_terms \n",
    "        if i[\"name\"].lower() == term[\"term\"].lower()\n",
    "    ]\n",
    "\n",
    "    if not matching_terms:\n",
    "        term.update({\n",
    "            \"valid_term\": False,\n",
    "            \"usable_term\": False\n",
    "        })\n",
    "\n",
    "    elif len(matching_terms) == 1:\n",
    "        term.update({\n",
    "            \"valid_term\": True,\n",
    "            \"usable_term\": True\n",
    "        })\n",
    "        term.update(matching_terms[0])\n",
    "\n",
    "    elif len(matching_terms) > 1:\n",
    "        thesaurus_match = next((i for i in matching_terms if i[\"thesaurus_id\"] == 2), None)\n",
    "        term.update({\"possible_sources\": [i for i in matching_terms if i[\"thesaurus_id\"] != 2]})\n",
    "        if thesaurus_match is not None:\n",
    "            term.update({\n",
    "                \"valid_term\": True, \n",
    "                \"usable_term\": True\n",
    "            })\n",
    "            term.update(thesaurus_match)\n",
    "        else:\n",
    "            term.update({\n",
    "                \"valid_term\": True,\n",
    "                \"usable_term\": False,\n",
    "                \"number_results\": len(matching_terms),\n",
    "                \"thesaurus_names\": list(set([i[\"thesaurus_name\"] for i in matching_terms]))\n",
    "            })\n",
    "    \n",
    "    term_eval.append(term)\n",
    "\n",
    "place_eval = list()\n",
    "def accumulator_places(term):\n",
    "    matching_terms = [\n",
    "        i for i in geo_names \n",
    "        if i[\"name\"].lower() == term[\"term\"].lower()\n",
    "    ]\n",
    "\n",
    "    if not matching_terms:\n",
    "        term.update({\n",
    "            \"valid_term\": False,\n",
    "            \"usable_term\": False\n",
    "        })\n",
    "\n",
    "    elif len(matching_terms) == 1:\n",
    "        term.update({\n",
    "            \"valid_term\": True,\n",
    "            \"usable_term\": True\n",
    "        })\n",
    "        term.update(matching_terms[0])\n",
    "\n",
    "    elif len(matching_terms) > 1:\n",
    "        term.update({\"possible_sources\": matching_terms})\n",
    "        first_match = term[\"possible_sources\"][0]\n",
    "        term.update({\n",
    "            \"valid_term\": True, \n",
    "            \"usable_term\": True\n",
    "        })\n",
    "        term.update(first_match)\n",
    "    \n",
    "    place_eval.append(term)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you really really need to download the USGS Thesaurus DB from source? [Y/n]: Y\n",
      "CPU times: user 761 ms, sys: 96.8 ms, total: 857 ms\n",
      "Wall time: 6.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if click.confirm('Do you really really need to download the USGS Thesaurus DB from source?', default=True):\n",
    "    r = requests.get(\"https://apps.usgs.gov/thesaurus/download/thesauri.zip\", stream=True)\n",
    "    if r.status_code == 200:\n",
    "        with open(isaid_helpers.f_usgs_thesaurus_source, 'wb') as f:\n",
    "            for chunk in r:\n",
    "                f.write(chunk)\n",
    "    if os.path.exists(isaid_helpers.f_usgs_thesaurus_source):\n",
    "        with zipfile.ZipFile(isaid_helpers.f_usgs_thesaurus_source, 'r') as f:\n",
    "            f.extractall(isaid_helpers.local_cache_path_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_thesaurus = sqlite3.connect(\"thesauri.db\")\n",
    "df_thesaurus = pd.read_sql_query(\"SELECT * from thesaurus\", con_thesaurus)\n",
    "\n",
    "all_terms = list()\n",
    "\n",
    "for index, row in df_thesaurus.iterrows():\n",
    "    try:\n",
    "        df = pd.read_sql_query(f\"SELECT * FROM {row.tblname}\", con)\n",
    "        df[\"thesaurus_name\"] = row[\"name\"]\n",
    "        df[\"thesaurus_id\"] = row[\"tag\"]\n",
    "        d = df.to_dict(orient=\"records\")\n",
    "        all_terms.extend(d)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    Parallel(n_jobs=50, prefer=\"threads\")(\n",
    "        delayed(accumulator)\n",
    "        (\n",
    "            i\n",
    "        ) for i in tqdm(declared_terms)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Terms declared as USGS Thesaurus but not in USGS Thesaurus:\", len([i for i in term_eval if not i[\"usable_term\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_url(thesaurus_id, code):\n",
    "    return f\"https://apps.usgs.gov/thesaurus/term-simple.php??thcode={code}&code={thesaurus_id}\"\n",
    "\n",
    "df_usable_terms = pd.DataFrame([i for i in term_eval if i[\"usable_term\"]])\n",
    "df_usable_terms[\"url\"] = df_usable_terms.apply(lambda x: add_url(x.thesaurus_id, x.code), axis=1)\n",
    "\n",
    "df_usable_terms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usable_terms.to_csv(isaid_helpers.f_graphable_thesaurus_terms, index=False)\n",
    "print(\n",
    "    isaid_helpers.f_graphable_thesaurus_terms, \n",
    "    \"CREATED\", \n",
    "    datetime.datetime.fromtimestamp(os.path.getmtime(isaid_helpers.f_graphable_thesaurus_terms))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if click.confirm('Do you really really need to download the Common Geographic Areas DB from source?', default=True):\n",
    "    r = requests.get(\"https://apps.usgs.gov/thesaurus/cga/CommonGeographicAreas.db\", stream=True)\n",
    "    if r.status_code == 200:\n",
    "        with open(isaid_helpers.f_common_geo_areas, 'wb') as f:\n",
    "            for chunk in r:\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_geo_areas = sqlite3.connect(isaid_helpers.f_common_geo_areas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo_names = pd.read_sql_query(\"SELECT * from geo\", con_geo_areas)\n",
    "df_geo_names[\"thesaurus_name\"] = \"Common geographic areas (USGS Thesaurus)\"\n",
    "geo_names = df_geo_names.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    Parallel(n_jobs=50, prefer=\"threads\")(\n",
    "        delayed(accumulator_places)\n",
    "        (\n",
    "            i\n",
    "        ) for i in tqdm(declared_places)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Terms declared as 'places' but not in USGS Thesaurus' Common Geographic Areas:\", len([i for i in place_eval if not i[\"usable_term\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usable_places = pd.DataFrame([i for i in place_eval if i[\"usable_term\"]])\n",
    "\n",
    "df_usable_places.to_csv(isaid_helpers.f_graphable_place_names, index=False)\n",
    "print(\n",
    "    isaid_helpers.f_graphable_place_names, \n",
    "    \"CREATED\", \n",
    "    datetime.datetime.fromtimestamp(os.path.getmtime(isaid_helpers.f_graphable_place_names))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usable_places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
